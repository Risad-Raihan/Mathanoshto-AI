# Product Requirements Document (PRD)
# Mathanoshto AI - Advanced Conversational AI Platform

**Project Name:** Mathanoshto AI  
**Version:** 1.0 (Developer Branch)  
**Document Version:** 1.0  
**Last Updated:** November 12, 2025  
**Status:** Development  
**Author:** Development Team  

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Product Overview](#2-product-overview)
3. [Target Users](#3-target-users)
4. [Core Features](#4-core-features)
5. [Technical Architecture](#5-technical-architecture)
6. [Functional Requirements](#6-functional-requirements)
7. [Non-Functional Requirements](#7-non-functional-requirements)
8. [User Interface & Experience](#8-user-interface--experience)
9. [Integration & APIs](#9-integration--apis)
10. [Data Management](#10-data-management)
11. [Security & Privacy](#11-security--privacy)
12. [Testing Requirements](#12-testing-requirements)
13. [Deployment & Operations](#13-deployment--operations)
14. [Future Roadmap](#14-future-roadmap)
15. [Glossary](#15-glossary)

---

## 1. Executive Summary

### 1.1 Product Vision

Mathanoshto AI is an advanced, production-grade conversational AI platform that provides users with an intelligent, context-aware AI assistant capable of performing complex tasks across multiple domains. The platform integrates cutting-edge AI technologies including large language models, retrieval-augmented generation (RAG), long-term memory systems, specialized AI agents, and multimodal capabilities.

### 1.2 Key Objectives

- **Intelligence:** Provide context-aware, intelligent responses using advanced LLM providers (OpenAI, Google Gemini, Anthropic)
- **Memory:** Implement long-term memory systems that learn from user interactions
- **Versatility:** Support multiple specialized AI agents for different tasks
- **Multimodal:** Handle text, images, documents, and data analysis
- **Integration:** Seamlessly integrate web search, document processing, and external tools
- **User Experience:** Deliver a modern, intuitive interface with rich features

### 1.3 Success Metrics

- User engagement and retention
- Response accuracy and relevance
- System performance (response time < 2 seconds)
- Feature adoption rate (memory, RAG, agents)
- User satisfaction scores

---

## 2. Product Overview

### 2.1 What is Mathanoshto AI?

Mathanoshto AI ("purai matha noshto" - "completely mind-blowing" in Bengali) is a full-stack conversational AI platform that goes beyond simple chatbots. It features:

- **Multiple LLM Providers:** OpenAI (GPT-4, GPT-4o), Google Gemini (Pro, Flash), and Anthropic Claude
- **Long-Term Memory:** ChromaDB-based semantic memory system that remembers user preferences and context
- **RAG System:** Document processing and retrieval for context-aware answers with citations
- **AI Agents:** 10+ specialized agents (Research, Code Review, Product, Architecture, ML, Debugging, etc.)
- **Multimodal Support:** Text, image upload, image generation (DALL-E, Stability AI), vision models
- **Advanced Tools:** Web search (Tavily), web scraping, YouTube summarization, data analysis, diagram generation
- **Smart Features:** Conversation summarization, insights, suggestions, prompt library, export

### 2.2 Platform Components

**Backend (Python):**
- FastAPI/Core Python backend
- SQLAlchemy ORM with SQLite/PostgreSQL
- Provider abstraction layer for LLMs
- Tool integrations (Tavily, Firecrawl, YouTube, etc.)
- RAG pipeline with chunking, embedding, retrieval
- Memory system with ChromaDB vector database
- Agent management system

**Frontend (Streamlit):**
- Modern, responsive UI with dark/light mode
- Chat interface with rich message formatting
- File upload and management
- Image gallery
- Agent selector
- Memory manager
- Conversation insights panel
- Diagram generator

### 2.3 Technology Stack

**Core Technologies:**
- **Language:** Python 3.8+
- **Frontend:** Streamlit 1.30+
- **Database:** SQLAlchemy with SQLite (development) / PostgreSQL (production)
- **Vector Database:** ChromaDB 0.4+
- **Embeddings:** Sentence Transformers (all-MiniLM-L6-v2)
- **LLM Providers:** OpenAI, Google Gemini, Anthropic
- **Image Processing:** Pillow, PyMuPDF
- **Document Processing:** PyPDF2, pdfplumber, python-docx

**Third-Party Services:**
- Tavily API (web search)
- Firecrawl (web scraping)
- DALL-E 3 / Stability AI (image generation)
- Kroki (diagram generation)
- YouTube Transcript API

---

## 3. Target Users

### 3.1 Primary Users

1. **Developers & Engineers**
   - Need code review, debugging assistance
   - Require architecture advice and technical documentation
   - Use for learning new technologies and frameworks

2. **Researchers & Students**
   - Academic research and paper analysis
   - Literature reviews and summarization
   - Learning complex topics with personalized explanations

3. **Product Managers & Business Professionals**
   - Product strategy and feature brainstorming
   - Market research and competitive analysis
   - Business document processing and insights

4. **Data Analysts**
   - Data analysis and visualization
   - Statistical analysis and interpretation
   - Working with CSV, Excel files

### 3.2 User Personas

**Persona 1: "Alex - Software Developer"**
- Age: 28, Mid-level backend developer
- Goals: Get code reviews, debug issues, learn new frameworks
- Pain Points: Context switching between tools, repetitive documentation
- Usage: Daily, 2-3 hours, primarily for code-related tasks

**Persona 2: "Sarah - Graduate Researcher"**
- Age: 25, PhD candidate in Computer Science
- Goals: Analyze research papers, track learnings, literature review
- Pain Points: Managing large amounts of research material
- Usage: Daily, 1-2 hours, primarily for research assistance

**Persona 3: "Mike - Product Manager"**
- Age: 35, Senior Product Manager
- Goals: Feature brainstorming, competitive analysis, PRD creation
- Pain Points: Information overload, need for structured thinking
- Usage: 3-4 times/week, primarily for strategic planning

---

## 4. Core Features

### 4.1 Conversational AI Chat

**Description:** Primary interface for user-AI interaction with rich formatting and multi-turn conversations.

**Key Capabilities:**
- Multi-turn conversations with context preservation
- Support for multiple LLM providers (OpenAI, Gemini, Anthropic)
- Model selection (GPT-4, GPT-4o, Gemini Pro, Gemini Flash, Claude)
- Adjustable parameters (temperature, max tokens, top-p, top-k)
- Real-time streaming responses
- Markdown rendering with code syntax highlighting
- Message history persistence

**User Stories:**
- US-001: As a user, I want to have natural conversations with AI that maintains context
- US-002: As a user, I want to switch between different LLM models based on my needs
- US-003: As a user, I want my conversation history to be saved and accessible

### 4.2 Long-Term Memory System

**Description:** Semantic memory system that learns and remembers user information across conversations.

**Key Capabilities:**
- Automatic memory extraction from conversations
- Manual memory creation and management
- 7 memory types: Personal Info, Preferences, Facts, Tasks, Goals, Relationships, Past Discussions
- Semantic search using sentence-transformers embeddings
- Memory importance scoring with decay algorithm
- Pin important memories for persistent recall
- Conflict resolution for contradicting information
- Version history tracking
- Automatic memory injection into conversation context

**User Stories:**
- US-010: As a user, I want the AI to remember my preferences across conversations
- US-011: As a user, I want to manually add important information to memory
- US-012: As a user, I want to search my memories by meaning, not just keywords
- US-013: As a user, I want important memories to always be included in context

**Technical Specifications:**
- **Vector Database:** ChromaDB with persistent storage
- **Embedding Model:** all-MiniLM-L6-v2 (384 dimensions)
- **Storage:** Local file system + ChromaDB
- **Retrieval:** Top-K similarity search (default K=10)
- **Minimum Similarity:** 0.6 (configurable)

### 4.3 RAG (Retrieval-Augmented Generation) System

**Description:** Production-grade document processing and retrieval system for context-aware responses with citations.

**Key Capabilities:**
- Multi-format file support (PDF, DOCX, TXT, CSV, Excel)
- 8 chunking strategies (recursive, semantic, overlap, token-aware, code-aware, etc.)
- Fast embedding generation with caching
- Hybrid search (BM25 + Semantic + RRF fusion)
- MMR re-ranking for diversity
- Automatic citation generation (inline, numbered, footnote, markdown formats)
- Context compression and query expansion
- Per-user configuration

**User Stories:**
- US-020: As a user, I want to upload documents and ask questions about them
- US-021: As a user, I want answers with citations to source documents
- US-022: As a user, I want the system to find relevant information across multiple documents
- US-023: As a user, I want to customize chunking and retrieval strategies

**Technical Specifications:**
- **Chunking:** 1000 chars default, 200 overlap
- **Embeddings:** Sentence-transformers (cached)
- **Retrieval:** Hybrid (70% semantic, 30% keyword)
- **Top-K:** 5 chunks default
- **Performance:** <500ms for 5 chunks
- **Accuracy:** 85%+ relevance

### 4.4 AI Agent System

**Description:** Specialized AI personas with unique expertise, system prompts, and tool permissions.

**Pre-defined Agents (10):**
1. **Research Agent** - AI research paper analysis (temp: 0.3)
2. **Code Reviewer** - Code quality, security, best practices (temp: 0.2)
3. **Product Discussion Partner** - Product strategy, UX (temp: 0.8)
4. **Architecture Advisor** - System design, scalability (temp: 0.4)
5. **ML Model Advisor** - Model training, hyperparameter tuning (temp: 0.3)
6. **Debugging Assistant** - Systematic debugging (temp: 0.2)
7. **Technical Writer** - Documentation, tutorials (temp: 0.4)
8. **Prompt Engineer** - LLM prompt optimization (temp: 0.5)
9. **Data Analyst** - Data analysis, visualization (temp: 0.3)
10. **Startup Advisor** - Business strategy, fundraising (temp: 0.7)

**Key Capabilities:**
- Custom agent creation with personalized system prompts
- Temperature and parameter customization per agent
- Tool permission management (selective tool access)
- Agent usage tracking and statistics
- Agent versioning and change history
- Agent categories and tags for organization

**User Stories:**
- US-030: As a user, I want to select specialized agents for different tasks
- US-031: As a developer, I want to create custom agents for my workflow
- US-032: As a user, I want agents to have appropriate tool permissions
- US-033: As a user, I want to track which agents are most helpful

**Technical Specifications:**
- **Storage:** SQLAlchemy database (agents, agent_versions, agent_sessions tables)
- **Categories:** Research, Development, Product, Data/AI, Business, Documentation
- **Version Control:** Full history of system prompt changes

### 4.5 Multimodal Image System

**Description:** Comprehensive image handling including upload, generation, and vision model support.

**Key Capabilities:**
- **Image Upload:** PNG, JPG, JPEG, GIF, WEBP, BMP (max 10MB, 4096px)
- **Clipboard Paste:** Direct paste from clipboard (Ctrl+V)
- **AI Image Generation:**
  - DALL-E 3 (OpenAI): 1024x1024, 1792x1024, 1024x1792
  - Stability AI: Stable Diffusion XL with custom parameters
- **Vision Models:** GPT-4V, GPT-4o, Gemini Pro Vision
- **Image Gallery:** View, sort, filter, download, delete images
- **Search Integration:** Automatic image extraction from Tavily search results

**User Stories:**
- US-040: As a user, I want to upload images and ask questions about them
- US-041: As a user, I want to generate images using AI
- US-042: As a user, I want to paste images directly from clipboard
- US-043: As a user, I want to browse and manage all my images

**Technical Specifications:**
- **Storage:** File system (uploads/images/, uploads/generated_images/, uploads/search_images/)
- **Image Processing:** Pillow for validation, resizing, format conversion
- **Thumbnail Generation:** Automatic thumbnail creation
- **Vision Models:** Automatic detection and proper formatting per provider

### 4.6 Advanced Tools Integration

**Description:** Integration of powerful external tools for extended capabilities.

**Tools Available:**

1. **Tavily Web Search**
   - Real-time web search with AI summaries
   - Image extraction and caching
   - Advanced search depth
   - Automatic result formatting

2. **Web Scraping**
   - Firecrawl integration for JavaScript-rendered pages
   - Beautiful Soup for HTML parsing
   - Readability extraction for clean content
   - robots.txt compliance

3. **YouTube Summarization**
   - Transcript extraction and processing
   - Video metadata retrieval
   - Duration and view count analysis
   - Smart summarization

4. **Data Analysis**
   - CSV/Excel file analysis
   - Statistical analysis (mean, median, correlation, etc.)
   - Data visualization (matplotlib, seaborn, plotly)
   - SQL query support

5. **Diagram Generation**
   - Mermaid, PlantUML, GraphViz support
   - 10+ diagram types (flowchart, sequence, class, ER, etc.)
   - SVG output via Kroki service
   - Automatic diagram saving

6. **Image Generation**
   - DALL-E 3 integration
   - Stability AI integration
   - Multiple sizes and quality options
   - Style control (vivid/natural)

**User Stories:**
- US-050: As a user, I want to search the web for current information
- US-051: As a user, I want to scrape and analyze web pages
- US-052: As a user, I want to get summaries of YouTube videos
- US-053: As a user, I want to analyze CSV/Excel files
- US-054: As a user, I want to generate diagrams from descriptions

### 4.7 Smart Conversation Features

**Description:** AI-powered features for conversation intelligence and management.

**Key Capabilities:**

1. **Conversation Summarization**
   - Multi-level summaries (short, medium, detailed)
   - Key points extraction
   - Decisions tracking
   - Action items identification
   - Important questions capture

2. **Conversation Suggestions**
   - Context-aware continuation suggestions
   - Conversation type detection (problem-solving, exploratory, etc.)
   - 5 suggestion categories (clarification, expansion, deep-dive, related, next steps)
   - Priority-based ranking

3. **Smart Prompt Library**
   - 16 built-in prompt templates
   - 5 categories (Learning, Problem-solving, Implementation, Planning, Analysis)
   - 3 complexity levels (Beginner, Intermediate, Advanced)
   - User custom prompt creation and management
   - Context-aware recommendations

4. **Conversation Insights**
   - Topic extraction with scoring
   - Entity recognition (technology, concepts, products)
   - Relationship mapping
   - Complexity assessment
   - Statistics dashboard (message counts, engagement ratio, etc.)

5. **Conversation Export**
   - 3 formats: Markdown, JSON, HTML
   - Executive summary integration
   - Privacy mode with sensitive data redaction
   - Beautiful HTML styling
   - Export metadata tracking

**User Stories:**
- US-060: As a user, I want automatic summaries of long conversations
- US-061: As a user, I want smart suggestions for continuing conversations
- US-062: As a user, I want access to helpful prompt templates
- US-063: As a user, I want insights into my conversation topics
- US-064: As a user, I want to export conversations in multiple formats

### 4.8 File Management

**Description:** Comprehensive file upload, processing, and management system.

**Key Capabilities:**
- Multi-file upload support
- File type detection and validation
- Thumbnail generation for documents
- File metadata tracking (size, upload date, format)
- File viewer and previewer
- File deletion and management
- Integration with RAG system for automatic processing

**Supported File Types:**
- **Documents:** PDF, DOCX, TXT
- **Data:** CSV, XLSX, XLS
- **Images:** PNG, JPG, JPEG, GIF, WEBP, BMP
- **Code:** (parsed as text)

**User Stories:**
- US-070: As a user, I want to upload multiple files at once
- US-071: As a user, I want to preview files before processing
- US-072: As a user, I want to manage and delete uploaded files
- US-073: As a user, I want files to be automatically processed for RAG

---

## 5. Technical Architecture

### 5.1 System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend Layer (Streamlit)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Chat Interface        â€¢ Agent Selector                    â”‚
â”‚  â€¢ File Manager          â€¢ Memory Manager                    â”‚
â”‚  â€¢ Image Gallery         â€¢ Insights Panel                    â”‚
â”‚  â€¢ Diagram Generator     â€¢ Settings                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core Backend Layer                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Chat Manager          â€¢ Agent Manager                     â”‚
â”‚  â€¢ Memory Manager        â€¢ File Manager                      â”‚
â”‚  â€¢ RAG Processor         â€¢ Image Handler                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Provider Layer                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ OpenAI Provider       â€¢ Gemini Provider                   â”‚
â”‚  â€¢ Base Provider Interface                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Tools & Services Layer                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Tavily Search         â€¢ Web Scraper                       â”‚
â”‚  â€¢ YouTube Tool          â€¢ Data Analyzer                     â”‚
â”‚  â€¢ Image Generator       â€¢ Diagram Generator                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Layer                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ SQLAlchemy ORM        â€¢ ChromaDB (Vectors)               â”‚
â”‚  â€¢ SQLite/PostgreSQL     â€¢ File System                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Backend Architecture

**Directory Structure:**
```
backend/
â”œâ”€â”€ auth/                  # Authentication and authorization
â”œâ”€â”€ config/                # Configuration management (settings.py, models.yaml)
â”œâ”€â”€ core/                  # Core business logic
â”‚   â”œâ”€â”€ agent_manager.py           # Agent system
â”‚   â”œâ”€â”€ chat_manager.py            # Chat orchestration
â”‚   â”œâ”€â”€ memory_manager.py          # Memory system
â”‚   â”œâ”€â”€ memory_extractor.py        # Automatic memory extraction
â”‚   â”œâ”€â”€ file_manager.py            # File operations
â”‚   â”œâ”€â”€ image_handler.py           # Image processing
â”‚   â”œâ”€â”€ rag_processor.py           # RAG orchestration
â”‚   â”œâ”€â”€ rag_chunker.py             # Document chunking
â”‚   â”œâ”€â”€ rag_embedder.py            # Embedding generation
â”‚   â”œâ”€â”€ rag_retriever.py           # Hybrid retrieval
â”‚   â”œâ”€â”€ rag_reranker.py            # MMR re-ranking
â”‚   â”œâ”€â”€ rag_citations.py           # Citation generation
â”‚   â”œâ”€â”€ rag_optimizer.py           # Compression & expansion
â”‚   â”œâ”€â”€ conversation_summarizer.py # Summarization
â”‚   â”œâ”€â”€ conversation_suggestions.py # Smart suggestions
â”‚   â”œâ”€â”€ conversation_insights.py   # Topic extraction
â”‚   â”œâ”€â”€ conversation_exporter.py   # Export system
â”‚   â”œâ”€â”€ prompt_library.py          # Prompt templates
â”‚   â””â”€â”€ model_factory.py           # LLM provider factory
â”œâ”€â”€ database/              # Database models and operations
â”‚   â”œâ”€â”€ models.py                  # User, Conversation, Message
â”‚   â”œâ”€â”€ agent_models.py            # Agent, AgentVersion, AgentSession
â”‚   â”œâ”€â”€ memory_models.py           # Memory, MemoryRelationship
â”‚   â”œâ”€â”€ rag_models.py              # DocumentChunk, RAGConfig, RAGMetrics
â”‚   â”œâ”€â”€ conversation_insights_models.py # Insights models
â”‚   â”œâ”€â”€ operations.py              # CRUD operations
â”‚   â”œâ”€â”€ memory_operations.py       # Memory operations
â”‚   â””â”€â”€ rag_operations.py          # RAG operations
â”œâ”€â”€ providers/             # LLM provider implementations
â”‚   â”œâ”€â”€ base.py                    # Base provider interface
â”‚   â”œâ”€â”€ openai_provider.py         # OpenAI integration
â”‚   â””â”€â”€ gemini_provider.py         # Google Gemini integration
â”œâ”€â”€ tools/                 # External tool integrations
â”‚   â”œâ”€â”€ tavily_search.py           # Web search
â”‚   â”œâ”€â”€ scraper_tool.py            # Web scraping
â”‚   â”œâ”€â”€ youtube_tool.py            # YouTube integration
â”‚   â”œâ”€â”€ data_analyzer.py           # Data analysis
â”‚   â”œâ”€â”€ image_generator.py         # AI image generation
â”‚   â””â”€â”€ diagram_generator.py       # Diagram creation
â””â”€â”€ utils/                 # Utility modules
    â”œâ”€â”€ file_parser.py             # File parsing
    â”œâ”€â”€ file_storage.py            # File storage
    â”œâ”€â”€ link_preview.py            # Link preview extraction
    â””â”€â”€ thumbnail_generator.py     # Thumbnail generation
```

### 5.3 Frontend Architecture

**Directory Structure:**
```
frontend/streamlit/
â”œâ”€â”€ app.py                 # Main application entry point
â”œâ”€â”€ components/            # UI components
â”‚   â”œâ”€â”€ login.py                   # Login/registration
â”‚   â”œâ”€â”€ sidebar.py                 # Settings sidebar
â”‚   â”œâ”€â”€ chat.py                    # Chat interface (1039 lines)
â”‚   â”œâ”€â”€ profile.py                 # User profile
â”‚   â”œâ”€â”€ file_manager.py            # File management UI
â”‚   â”œâ”€â”€ image_gallery.py           # Image gallery (242 lines)
â”‚   â”œâ”€â”€ memory_manager.py          # Memory management UI
â”‚   â”œâ”€â”€ agent_manager.py           # Agent management UI
â”‚   â”œâ”€â”€ conversation_insights_panel.py # Insights UI
â”‚   â””â”€â”€ diagram_generator.py       # Diagram UI
â””â”€â”€ styles/                # Custom styling
    â””â”€â”€ custom_css.py              # CSS definitions (676 lines)
```

### 5.4 Database Schema

**Core Tables:**

1. **users** - User accounts
   - id, username, email, password_hash, full_name, created_at

2. **conversations** - Chat conversations
   - id, user_id, title, created_at, updated_at, message_count

3. **messages** - Chat messages
   - id, conversation_id, role (user/assistant), content, provider, model, created_at

4. **files** - Uploaded files
   - id, user_id, filename, file_path, file_type, file_size, created_at

5. **agents** - AI agents
   - id, name, emoji, description, system_prompt, temperature, max_tokens, category, tags, allowed_tools, usage_count, is_system, created_by

6. **agent_versions** - Agent version history
   - id, agent_id, version, system_prompt, settings, change_summary

7. **agent_sessions** - Agent usage tracking
   - id, agent_id, conversation_id, user_id, message_count, started_at, ended_at

8. **memories** - Long-term memory
   - id, user_id, content, memory_type, category, importance, is_pinned, is_verified, tags, last_accessed_at

9. **memory_relationships** - Memory connections
   - id, source_memory_id, target_memory_id, relationship_type

10. **document_chunks** - RAG chunks
    - id, file_id, user_id, chunk_text, chunk_index, embedding_id, metadata

11. **rag_configurations** - RAG settings per user
    - id, user_id, chunking_strategy, chunk_size, retrieval_mode, citation_format

12. **rag_metrics** - RAG performance tracking
    - id, user_id, query, retrieval_time, chunks_retrieved, files_covered

13. **conversation_summaries** - Conversation summaries
    - id, conversation_id, short_summary, medium_summary, detailed_summary, key_points, action_items

14. **conversation_insights** - Conversation analytics
    - id, conversation_id, main_topics, entities, relationships, conversation_type, complexity

15. **conversation_suggestions** - Smart suggestions
    - id, conversation_id, suggestion_text, category, priority

16. **conversation_exports** - Export tracking
    - id, conversation_id, user_id, export_format, file_path, created_at

17. **user_prompt_library** - Custom prompts
    - id, user_id, title, text, category, tags

### 5.5 Data Flow

**Chat Message Flow:**
```
1. User Input â†’ Frontend (chat.py)
2. Chat Manager â†’ Provider Selection
3. Memory Retrieval â†’ Relevant memories injected
4. Agent System â†’ Apply agent settings if active
5. RAG System â†’ Retrieve relevant document chunks if files attached
6. Tool Execution â†’ Call enabled tools if needed
7. LLM Provider â†’ Generate response
8. Response Processing â†’ Format, citations, images
9. Database â†’ Save message and metadata
10. Frontend â†’ Display formatted response
```

**RAG Processing Flow:**
```
1. File Upload â†’ File Manager
2. File Parsing â†’ Extract text
3. Chunking â†’ Split into chunks (8 strategies)
4. Embedding â†’ Generate vectors (sentence-transformers)
5. Storage â†’ Save chunks + embeddings
6. Query â†’ User asks question
7. Retrieval â†’ Hybrid search (BM25 + Semantic)
8. Re-ranking â†’ MMR for diversity
9. Citations â†’ Generate source references
10. Context â†’ Inject into LLM prompt
```

**Memory System Flow:**
```
1. Conversation â†’ User chats
2. Extraction â†’ Automatic memory detection
3. Embedding â†’ Generate memory vector
4. Storage â†’ Save to ChromaDB + SQLite
5. Query â†’ User sends new message
6. Retrieval â†’ Semantic search for relevant memories
7. Context â†’ Inject into system prompt
8. Update â†’ Update access counts and decay
```

---

## 6. Functional Requirements

### 6.1 User Management

**FR-001: User Registration**
- Users shall be able to create accounts with username, email, and password
- Passwords shall be hashed using bcrypt
- Email validation shall be performed
- Duplicate username/email shall be prevented

**FR-002: User Authentication**
- Users shall be able to log in with username/email and password
- Session management shall persist login state
- Logout functionality shall clear session

**FR-003: User Profile**
- Users shall be able to view and edit profile information
- Profile shall display account statistics (conversations, messages, memory count)

### 6.2 Chat & Conversations

**FR-010: Create Conversation**
- Users shall be able to start new conversations
- Conversations shall have auto-generated or custom titles
- Conversations shall be saved in database

**FR-011: Send Messages**
- Users shall be able to send text messages
- System shall support multi-line input
- Messages shall support markdown formatting

**FR-012: Receive Responses**
- AI responses shall stream in real-time
- Responses shall render markdown with code highlighting
- Responses shall include citations when using RAG

**FR-013: Conversation History**
- Users shall be able to view past conversations
- Conversations shall be sortable by date
- Users shall be able to search conversations

**FR-014: Delete Conversations**
- Users shall be able to delete conversations
- Deletion shall be soft delete with option for hard delete
- Associated messages and data shall be removed

**FR-015: Export Conversations**
- Users shall be able to export conversations
- Export formats: Markdown, JSON, HTML
- Exports shall include metadata and optional privacy mode

### 6.3 Model Selection & Configuration

**FR-020: Select LLM Provider**
- Users shall be able to select from available providers (OpenAI, Gemini, Anthropic)
- Provider selection shall persist across sessions
- Invalid API keys shall show clear error messages

**FR-021: Select Model**
- Users shall be able to select from available models per provider
- Model information (tokens, capabilities) shall be displayed
- Vision-capable models shall be automatically detected

**FR-022: Adjust Parameters**
- Users shall be able to adjust temperature (0.0 - 2.0)
- Users shall be able to adjust max tokens
- Users shall be able to adjust top-p and top-k (provider-dependent)
- Parameters shall have sensible defaults

**FR-023: Enable/Disable Tools**
- Users shall be able to toggle individual tools
- Tool availability shall depend on API key configuration
- Tools: Tavily Search, Web Scraper, YouTube, Data Analyzer, Image Generator

### 6.4 Memory System

**FR-030: Create Memory**
- Users shall be able to manually create memories
- Required fields: content, type, importance
- Optional fields: category, tags, pin status
- Memories shall be automatically embedded

**FR-031: View Memories**
- Users shall be able to view all memories
- Memories shall be filterable by type
- Memories shall be sortable by date, importance, access count

**FR-032: Search Memories**
- Users shall be able to perform semantic search
- Search shall return similarity scores
- Search shall support filtering by type

**FR-033: Edit Memory**
- Users shall be able to edit memory content
- Edits shall be versioned
- Importance and tags shall be editable

**FR-034: Delete Memory**
- Users shall be able to delete memories
- Deletion shall be soft delete by default
- Hard delete option shall be available

**FR-035: Pin Memory**
- Users shall be able to pin important memories
- Pinned memories shall always be included in context
- Maximum 5 pinned memories recommended

**FR-036: Auto-Extract Memories**
- System shall automatically extract memories from conversations
- Extraction shall be configurable (on/off, frequency)
- Extracted memories shall be reviewable before saving

**FR-037: Memory Injection**
- System shall automatically retrieve relevant memories for each message
- Top-K memories shall be injected into system prompt
- Minimum similarity threshold shall be configurable

### 6.5 RAG System

**FR-040: Upload Files**
- Users shall be able to upload PDF, DOCX, TXT, CSV, Excel files
- Files shall be validated for size (max 10MB) and format
- Files shall be saved with unique identifiers

**FR-041: Process Files**
- System shall extract text from documents
- System shall chunk documents using selected strategy
- System shall generate embeddings for chunks
- Processing status shall be visible to user

**FR-042: Configure RAG**
- Users shall be able to select chunking strategy
- Users shall be able to adjust chunk size and overlap
- Users shall be able to select retrieval mode (hybrid/semantic/keyword)
- Users shall be able to select citation format

**FR-043: Query Documents**
- Users shall be able to ask questions about uploaded documents
- System shall retrieve relevant chunks
- System shall re-rank results for diversity
- Responses shall include inline citations

**FR-044: View File Details**
- Users shall be able to view file metadata
- Users shall be able to see chunk count per file
- Users shall be able to preview file content

**FR-045: Delete Files**
- Users shall be able to delete uploaded files
- Deletion shall remove file, chunks, and embeddings
- Confirmation shall be required

### 6.6 AI Agents

**FR-050: Select Agent**
- Users shall be able to select from pre-defined agents
- Agent selection shall apply agent settings (temperature, system prompt, tools)
- Agent indicator shall be visible in chat

**FR-051: Create Custom Agent**
- Users shall be able to create custom agents
- Required fields: name, description, system prompt
- Optional fields: emoji, category, tags, tool permissions
- Agents shall be saved to database

**FR-052: Edit Agent**
- Users shall be able to edit custom agents (not system agents)
- Edits shall create new versions
- Change summary shall be optional

**FR-053: Delete Agent**
- Users shall be able to delete custom agents
- System agents shall not be deletable
- Confirmation shall be required

**FR-054: View Agent Stats**
- Users shall be able to view agent usage statistics
- Stats: usage count, average rating, sessions
- Most used agents shall be highlighted

**FR-055: Agent Tool Permissions**
- Agents shall have configurable tool permissions
- Only allowed tools shall be available during agent sessions
- Tool permissions shall be editable

### 6.7 Image System

**FR-060: Upload Images**
- Users shall be able to upload images (PNG, JPG, JPEG, GIF, WEBP, BMP)
- Images shall be validated (max 10MB, 4096px)
- Multiple images shall be uploadable simultaneously
- Images shall be previewed before sending

**FR-061: Paste Images**
- Users shall be able to paste images from clipboard (Ctrl+V)
- Pasted images shall be automatically attached
- Clipboard data shall be validated

**FR-062: Generate Images**
- Users shall be able to request AI image generation
- Providers: DALL-E 3, Stability AI
- Parameters: size, quality, style, negative prompt
- Generated images shall be saved and displayed

**FR-063: View Image Gallery**
- Users shall be able to view all images
- Gallery tabs: All, Uploaded, Generated, From Search
- Images shall be sortable by date, size
- Image metadata shall be displayed

**FR-064: Delete Images**
- Users shall be able to delete images
- Deletion shall remove file and thumbnail
- Confirmation shall be required

**FR-065: Vision Model Support**
- System shall support vision-capable models (GPT-4V, Gemini Vision)
- Images shall be properly formatted for each provider
- Multiple images per message shall be supported

### 6.8 Tools Integration

**FR-070: Web Search (Tavily)**
- Users shall be able to trigger web search via query or function call
- Search shall return results with AI summary
- Search shall optionally include images
- Results shall be cached

**FR-071: Web Scraping**
- Users shall be able to scrape web pages
- System shall handle JavaScript-rendered pages (Playwright)
- System shall extract clean content (Readability)
- System shall respect robots.txt

**FR-072: YouTube Summarization**
- Users shall be able to get YouTube video summaries
- System shall extract transcripts
- System shall provide metadata (duration, views)
- System shall generate concise summaries

**FR-073: Data Analysis**
- Users shall be able to upload CSV/Excel files
- System shall perform statistical analysis
- System shall generate visualizations
- Results shall be displayed inline

**FR-074: Diagram Generation**
- Users shall be able to generate diagrams from descriptions
- Supported types: Mermaid, PlantUML, GraphViz, etc.
- Diagrams shall be rendered as SVG
- Diagrams shall be saveable

### 6.9 Smart Features

**FR-080: Conversation Summarization**
- System shall automatically generate conversation summaries
- Summaries: short (1-2 lines), medium (paragraph), detailed (full)
- System shall extract key points, decisions, action items
- Summaries shall be accessible on demand

**FR-081: Conversation Suggestions**
- System shall generate context-aware continuation suggestions
- Categories: clarification, expansion, deep-dive, related, next steps
- Suggestions shall be prioritized
- Users shall be able to select suggestions to continue

**FR-082: Prompt Library**
- System shall provide 16 built-in prompt templates
- Categories: Learning, Problem-solving, Implementation, Planning, Analysis
- Users shall be able to create custom prompts
- Prompts shall be searchable and filterable

**FR-083: Conversation Insights**
- System shall extract topics from conversations
- System shall recognize entities (technology, concepts, products)
- System shall detect conversation type
- System shall provide statistics dashboard

---

## 7. Non-Functional Requirements

### 7.1 Performance

**NFR-001: Response Time**
- AI responses shall begin streaming within 2 seconds
- File upload processing shall complete within 30 seconds for files <10MB
- Memory retrieval shall complete within 500ms
- RAG retrieval shall complete within 500ms for 5 chunks
- Database queries shall complete within 100ms

**NFR-002: Throughput**
- System shall support 10 concurrent users (development)
- System shall support 100 concurrent users (production target)
- Memory embedding generation: 35 batches/second

**NFR-003: Scalability**
- System shall scale horizontally with load balancing
- Database shall support connection pooling
- Vector database shall support partitioning

### 7.2 Reliability

**NFR-010: Availability**
- System shall have 99% uptime (production target)
- Graceful degradation when external APIs are unavailable
- Retry logic for transient failures (3 attempts with exponential backoff)

**NFR-011: Data Integrity**
- All database operations shall use transactions
- Foreign key constraints shall be enforced
- Data validation shall occur at multiple layers

**NFR-012: Error Handling**
- All errors shall be logged with timestamps and context
- User-facing error messages shall be clear and actionable
- Critical errors shall not expose sensitive information

### 7.3 Security

**NFR-020: Authentication**
- Passwords shall be hashed using bcrypt (cost factor: 12)
- Session tokens shall expire after 30 days
- Failed login attempts shall be rate-limited

**NFR-021: Authorization**
- Users shall only access their own data
- Admin roles shall be supported for system management
- API keys shall be stored securely (environment variables)

**NFR-022: Data Protection**
- Sensitive data shall be encrypted at rest (future enhancement)
- API keys shall never be logged or exposed
- Privacy mode shall redact emails, phones, API keys, tokens

**NFR-023: API Security**
- Rate limiting shall be implemented (100 requests/minute per user)
- Input validation shall prevent injection attacks
- CORS policies shall be enforced

### 7.4 Usability

**NFR-030: User Interface**
- UI shall be responsive (desktop, tablet, mobile)
- UI shall support dark and light modes
- UI shall follow accessibility guidelines (WCAG 2.1 AA)

**NFR-031: Learnability**
- First-time users shall complete initial setup within 5 minutes
- Help documentation shall be accessible from UI
- Tooltips shall provide contextual help

**NFR-032: Error Messages**
- Error messages shall be user-friendly
- Error messages shall suggest corrective actions
- Error messages shall not expose technical details to users

### 7.5 Maintainability

**NFR-040: Code Quality**
- Code shall follow PEP 8 style guidelines
- Code shall be modular with single responsibility principle
- Functions shall have docstrings
- Type hints shall be used where applicable

**NFR-041: Testing**
- Unit test coverage shall be >80%
- Integration tests shall cover critical paths
- End-to-end tests shall cover main user flows

**NFR-042: Documentation**
- API functions shall be documented
- System architecture shall be documented
- Deployment procedures shall be documented
- User guides shall be maintained

### 7.6 Compatibility

**NFR-050: Browser Support**
- System shall support Chrome 90+, Firefox 88+, Safari 14+, Edge 90+
- JavaScript shall be required for full functionality

**NFR-051: Operating System**
- Backend shall run on Linux, macOS, Windows
- Python 3.8+ shall be required

**NFR-052: Database**
- System shall support SQLite (development) and PostgreSQL (production)
- Database migrations shall be versioned

---

## 8. User Interface & Experience

### 8.1 UI Components

**Main Application Layout:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ§  Mathanoshto AI                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          â”‚                                                   â”‚
â”‚ Sidebar  â”‚             Chat Area                            â”‚
â”‚          â”‚                                                   â”‚
â”‚ â€¢ Profileâ”‚  [Conversation Title]                            â”‚
â”‚ â€¢ Files  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â€¢ Memory â”‚  â”‚ User: How does RAG work?                â”‚    â”‚
â”‚ â€¢ Agents â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚ â€¢ Galleryâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â€¢ Insightsâ”‚ â”‚ AI: RAG combines retrieval and...       â”‚    â”‚
â”‚ â€¢ Settingsâ”‚ â”‚ [Source: document.pdf, p.5]             â”‚    â”‚
â”‚ â€¢ Diagram â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚          â”‚                                                   â”‚
â”‚ ğŸ”§ Tools â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â˜‘ Search â”‚  â”‚ Type your message...                    â”‚    â”‚
â”‚ â˜‘ RAG    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚ â˜ YouTubeâ”‚  [ğŸ“ Upload] [ğŸ–¼ï¸ Image] [Send]                â”‚
â”‚          â”‚                                                   â”‚
â”‚ ğŸ¤– Agent â”‚                                                   â”‚
â”‚ Research â”‚                                                   â”‚
â”‚          â”‚                                                   â”‚
â”‚ Model    â”‚                                                   â”‚
â”‚ GPT-4    â”‚                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Key Screens

**1. Login/Registration Screen**
- Clean, centered layout
- Username/email and password fields
- "Remember me" checkbox
- "Sign in" and "Create account" options
- Password visibility toggle

**2. Chat Interface**
- Full-width conversation area
- Message bubbles with distinct user/AI styling
- Streaming indicator for AI responses
- Code blocks with syntax highlighting
- Image previews
- Citation links
- Timestamp display

**3. Sidebar**
- Collapsible sections
- Settings panel (provider, model, parameters)
- Tools toggles
- Agent selector
- Quick access icons (Profile, Files, Memory, Gallery, Insights, Diagram)
- Dark/light mode toggle

**4. Memory Manager**
- Tabs: All Memories, Add Memory, Search, Settings
- Memory cards with content, type, importance
- Pin, edit, delete actions
- Search bar with filters
- Statistics display

**5. File Manager**
- File list with thumbnails
- Upload button with drag-and-drop
- File metadata (size, date, type)
- Preview, download, delete actions
- Processing status indicator

**6. Image Gallery**
- Tabs: All, Uploaded, Generated, From Search
- Grid layout (3 columns)
- Image cards with preview
- Sorting options (newest, oldest, largest, smallest)
- View, download, delete actions

**7. Agent Manager**
- Tabs: All Agents, Create Agent, Edit Agent, Stats
- Agent cards with emoji, name, description
- Filter by category
- Usage statistics
- Create/edit forms

**8. Conversation Insights Panel**
- Summary section (short, medium, detailed)
- Topics cloud or list
- Entities list with categories
- Statistics dashboard
- Export button

**9. Diagram Generator**
- Diagram type selector
- Code editor for diagram syntax
- Live preview
- Generate and save buttons
- Example templates

### 8.3 Design Principles

**Visual Design:**
- Modern, clean aesthetic
- Consistent color palette
- Adequate whitespace
- Clear visual hierarchy
- Subtle animations and transitions

**Interaction Design:**
- Immediate feedback for all actions
- Loading states for async operations
- Confirmation dialogs for destructive actions
- Keyboard shortcuts for common actions
- Hover states for interactive elements

**Information Architecture:**
- Logical grouping of related features
- Clear navigation paths
- Breadcrumbs for deep navigation
- Search functionality where appropriate
- Context-sensitive help

**Accessibility:**
- High contrast ratios (WCAG AA)
- Keyboard navigation support
- Screen reader compatibility
- Focus indicators
- Alt text for images

### 8.4 Theme System

**Dark Mode (Default):**
- Background: Dark gray/black gradients
- Text: White/light gray
- Accent colors: Blue, purple, cyan
- Code blocks: Monokai/Dark theme

**Light Mode:**
- Background: White/light gray
- Text: Dark gray/black
- Accent colors: Blue, teal, green
- Code blocks: GitHub/Light theme

**Color Palette System:**
- Primary: Blue (#3b82f6)
- Secondary: Purple (#8b5cf6)
- Success: Green (#10b981)
- Warning: Yellow (#f59e0b)
- Error: Red (#ef4444)
- Info: Cyan (#06b6d4)

---

## 9. Integration & APIs

### 9.1 External API Integrations

**OpenAI API**
- **Purpose:** GPT-4, GPT-4o, GPT-4V models, DALL-E 3 image generation
- **Authentication:** API key (OPENAI_API_KEY)
- **Endpoints Used:**
  - `/v1/chat/completions` - Chat completions
  - `/v1/images/generations` - Image generation
- **Rate Limits:** Tier-based (varies by account)
- **Error Handling:** Retry with exponential backoff, fallback to other providers

**Google Gemini API**
- **Purpose:** Gemini Pro, Gemini Flash, Gemini Pro Vision models
- **Authentication:** API key (GEMINI_API_KEY)
- **Endpoints Used:**
  - `generateContent` - Chat completions
  - `embedContent` - Text embeddings (if used)
- **Rate Limits:** 60 requests/minute (free tier)
- **Error Handling:** Queue requests, retry on failure

**Anthropic API (Planned)**
- **Purpose:** Claude models
- **Authentication:** API key (ANTHROPIC_API_KEY)
- **Endpoints Used:**
  - `/v1/messages` - Chat completions
- **Rate Limits:** Tier-based
- **Error Handling:** Standard retry logic

**Tavily API**
- **Purpose:** Web search with AI summaries
- **Authentication:** API key (TAVILY_API_KEY)
- **Endpoints Used:**
  - `/search` - Web search
- **Rate Limits:** Based on plan
- **Error Handling:** Fallback to manual search

**Firecrawl API (Optional)**
- **Purpose:** Advanced web scraping
- **Authentication:** API key (FIRECRAWL_API_KEY)
- **Endpoints Used:**
  - `/scrape` - Scrape single URL
  - `/crawl` - Crawl multiple pages
- **Rate Limits:** Based on plan
- **Error Handling:** Fallback to BeautifulSoup scraping

**Stability AI API (Optional)**
- **Purpose:** Stable Diffusion image generation
- **Authentication:** API key (STABILITY_API_KEY)
- **Endpoints Used:**
  - `/v1/generation/{engine_id}/text-to-image`
- **Rate Limits:** Credit-based
- **Error Handling:** Clear error messages, fallback to DALL-E

**Kroki Service**
- **Purpose:** Diagram generation
- **Authentication:** None (public service)
- **Endpoints Used:**
  - `/{diagram_type}/svg` - Generate SVG diagrams
- **Rate Limits:** Reasonable use policy
- **Error Handling:** Timeout after 10 seconds

**YouTube Transcript API**
- **Purpose:** Video transcript extraction
- **Authentication:** None (uses yt-dlp/youtube-transcript-api)
- **Endpoints Used:**
  - YouTube Data API v3 (for metadata)
- **Rate Limits:** 10,000 requests/day (YouTube API)
- **Error Handling:** Handle missing transcripts, language fallbacks

### 9.2 Internal API Architecture

**Provider Factory Pattern:**
```python
class BaseLLMProvider:
    def chat_completion(self, messages, **kwargs)
    def stream_completion(self, messages, **kwargs)
    def count_tokens(self, text)
    def supports_vision(self)
    def supports_function_calling(self)
```

**Tool Integration Pattern:**
```python
class BaseTool:
    @staticmethod
    def get_tool_definition() -> Dict
    def execute(self, function_args: Dict) -> str
```

### 9.3 Future API Endpoints (Planned)

**REST API for Programmatic Access:**

```
POST /api/v1/conversations
POST /api/v1/conversations/{id}/messages
GET  /api/v1/conversations/{id}
DELETE /api/v1/conversations/{id}

POST /api/v1/memories
GET  /api/v1/memories
PUT  /api/v1/memories/{id}
DELETE /api/v1/memories/{id}
POST /api/v1/memories/search

POST /api/v1/files
GET  /api/v1/files
DELETE /api/v1/files/{id}

GET  /api/v1/agents
POST /api/v1/agents
PUT  /api/v1/agents/{id}
DELETE /api/v1/agents/{id}

POST /api/v1/conversations/{id}/summarize
POST /api/v1/conversations/{id}/insights
POST /api/v1/conversations/{id}/suggestions
POST /api/v1/conversations/{id}/export
```

---

## 10. Data Management

### 10.1 Database Strategy

**Development:**
- SQLite database (`chat_history.db`)
- File-based, portable
- Suitable for single-user/testing

**Production:**
- PostgreSQL database
- Connection pooling
- Backup and replication
- Scalable for multi-user

### 10.2 Data Storage

**Structured Data (SQLite/PostgreSQL):**
- User accounts
- Conversations and messages
- Agents and versions
- File metadata
- RAG configurations and metrics
- Conversation insights and summaries

**Vector Data (ChromaDB):**
- Memory embeddings (persistent storage in `data/chroma_db/`)
- Query: Semantic similarity search
- Local embeddings (no API calls)

**File System:**
- Uploaded files (`uploads/`)
- Generated images (`uploads/generated_images/`)
- Search images (`uploads/search_images/`)
- User images (`uploads/images/`)
- Document thumbnails (`uploads/thumbnails/`)
- Diagrams (`output/diagrams/`)
- Exports (`exports/`)
- Visualizations (`uploads/visualizations/`)
- RAG embeddings cache (`data/rag_embeddings/`)

### 10.3 Data Retention

**Conversations:**
- Retention: Indefinite (user-controlled deletion)
- Soft delete: Mark as deleted but keep in DB for 30 days
- Hard delete: Permanent removal after 30 days

**Files:**
- Retention: Until user deletion
- Cleanup: Automatic removal of unreferenced files (weekly job)

**Memories:**
- Retention: Indefinite with importance decay
- Low-importance memories: Auto-archive after 180 days

**Images:**
- Uploaded: User-controlled retention
- Generated: 90 days auto-cleanup (configurable)
- Search cache: 7 days auto-cleanup

**Exports:**
- Retention: 30 days
- Cleanup: Automatic removal

### 10.4 Backup Strategy

**Database:**
- Daily automated backups
- 7-day retention
- Point-in-time recovery capability

**Files:**
- Weekly backups to cloud storage (S3/GCS)
- 30-day retention

**ChromaDB:**
- Weekly backups
- Stored alongside database backups

### 10.5 Data Migration

**Version Control:**
- Database schema versioned (Alembic for migrations)
- Migration scripts for schema changes
- Rollback capability

**Data Import/Export:**
- User data export (JSON format)
- Conversation export (MD, JSON, HTML)
- Memory export/import (future feature)

---

## 11. Security & Privacy

### 11.1 Authentication & Authorization

**Authentication:**
- Bcrypt password hashing (cost factor: 12)
- Session-based authentication (Streamlit session state)
- Session timeout: 30 days (configurable)
- Password requirements: Minimum 8 characters, complexity rules

**Authorization:**
- User-level access control (users only access their own data)
- Admin role for system management (future)
- API key security (never logged or exposed)

### 11.2 Data Security

**In Transit:**
- HTTPS enforced (production)
- TLS 1.2+ for all external API calls

**At Rest:**
- Database encryption (production, using PostgreSQL encryption)
- File system encryption (OS-level)
- API keys stored in environment variables, never in code

**Sensitive Data:**
- Privacy mode redacts: emails, phone numbers, API keys, tokens
- Passwords never stored in plaintext
- User data isolated (no cross-user access)

### 11.3 Privacy

**Data Collection:**
- Only essential data collected (conversations, files, settings)
- No telemetry or analytics without user consent
- User data never sold or shared

**Third-Party Services:**
- LLM providers (OpenAI, Google, Anthropic): Conversations sent for processing
- API policies: Users' own keys = users' own responsibility
- No training: User data not used to train models (per provider policies)

**Data Deletion:**
- Users can delete conversations, files, memories at any time
- Soft delete with 30-day grace period
- Hard delete permanently removes all traces

**Compliance:**
- GDPR-ready (data export, deletion, transparency)
- User consent for data processing
- Privacy policy and terms of service (to be added)

### 11.4 Security Best Practices

**Input Validation:**
- All user inputs validated and sanitized
- SQL injection prevention (parameterized queries)
- XSS prevention (escaped HTML in outputs)
- File upload validation (type, size, content)

**Rate Limiting:**
- API endpoints: 100 requests/minute per user
- Login attempts: 5 attempts per 15 minutes
- File uploads: 10 files per minute

**Error Handling:**
- No sensitive information in error messages
- Stack traces hidden from users (logged server-side)
- Generic error messages for security-related failures

**Logging:**
- All API calls logged with timestamps
- User actions logged (login, file upload, etc.)
- No logging of passwords, API keys, or sensitive content
- Logs rotated and retained for 90 days

---

## 12. Testing Requirements

### 12.1 Unit Testing

**Coverage Target:** 80%+

**Core Modules to Test:**
- `chat_manager.py` - Message handling, provider orchestration
- `memory_manager.py` - Memory CRUD operations, retrieval
- `rag_processor.py` - Chunking, embedding, retrieval
- `agent_manager.py` - Agent selection, settings application
- `image_handler.py` - Image validation, processing, storage
- `conversation_summarizer.py` - Summary generation
- `conversation_insights.py` - Topic extraction
- `prompt_library.py` - Prompt retrieval, suggestions

**Test Framework:**
- pytest for test execution
- pytest-asyncio for async tests
- pytest-mock for mocking external APIs
- pytest-cov for coverage reporting

**Example Test Cases:**
- Test message sending with different providers
- Test memory retrieval with varying similarity thresholds
- Test RAG chunking with different strategies
- Test agent system prompt injection
- Test image validation with invalid files

### 12.2 Integration Testing

**Critical Paths:**
1. **End-to-End Chat Flow**
   - User logs in â†’ creates conversation â†’ sends message â†’ receives response â†’ views history

2. **RAG Pipeline**
   - Upload file â†’ process â†’ chunk â†’ embed â†’ query â†’ retrieve â†’ cite

3. **Memory System**
   - Create memory â†’ embed â†’ query â†’ retrieve â†’ inject into chat

4. **Agent System**
   - Select agent â†’ apply settings â†’ send message â†’ verify agent behavior

5. **Image System**
   - Upload image â†’ validate â†’ send with vision model â†’ receive analysis

**Test Data:**
- Sample conversations
- Sample documents (PDF, DOCX, TXT, CSV)
- Sample images
- Mock API responses

### 12.3 End-to-End Testing

**Test Scenarios:**

**Scenario 1: New User Onboarding**
1. User visits application
2. Creates account
3. Logs in
4. Completes initial setup (API key, preferences)
5. Sends first message
6. Receives response
7. Expected: Smooth onboarding, no errors

**Scenario 2: Document Q&A**
1. User uploads PDF document
2. System processes and chunks document
3. User asks question about document
4. System retrieves relevant chunks
5. Response includes citations
6. Expected: Accurate answer with source references

**Scenario 3: Multi-Agent Workflow**
1. User selects Research Agent
2. Asks about AI research topic
3. Switches to Code Reviewer Agent
4. Asks for code review
5. Expected: Distinct agent behaviors, appropriate responses

**Scenario 4: Image Generation & Vision**
1. User requests image generation
2. System generates image via DALL-E
3. User uploads image and asks about it
4. System analyzes with GPT-4V
5. Expected: Generated image displayed, accurate analysis

**Test Tools:**
- Playwright for browser automation
- Selenium as fallback
- TestSprite for comprehensive testing (as mentioned by user)

### 12.4 Performance Testing

**Load Testing:**
- Simulate 10 concurrent users
- Measure response times, throughput
- Identify bottlenecks
- Tools: Locust, Apache JMeter

**Stress Testing:**
- Push system beyond normal capacity
- Identify breaking points
- Verify graceful degradation
- Tools: Locust with ramping

**Benchmarks:**
- Chat response: <2 seconds to first token
- File upload: <30 seconds for 10MB
- Memory retrieval: <500ms
- RAG retrieval: <500ms for 5 chunks
- Database query: <100ms

### 12.5 Security Testing

**Penetration Testing:**
- SQL injection attempts
- XSS attack vectors
- CSRF vulnerabilities
- Authentication bypass attempts

**Vulnerability Scanning:**
- Dependency scanning (pip-audit, safety)
- Code analysis (Bandit for Python)
- OWASP Top 10 checklist

**Authentication Testing:**
- Password strength validation
- Session hijacking attempts
- Rate limiting verification
- API key security

### 12.6 Usability Testing

**User Acceptance Testing:**
- Recruit 5-10 users from target personas
- Task-based scenarios
- Observe user behavior
- Collect feedback (System Usability Scale)

**A/B Testing:**
- Test UI variations
- Measure task completion rates
- Measure time on task
- Gather user preferences

**Accessibility Testing:**
- Screen reader compatibility (NVDA, JAWS)
- Keyboard navigation
- Color contrast validation
- WCAG 2.1 AA compliance

---

## 13. Deployment & Operations

### 13.1 Deployment Architecture

**Development Environment:**
- Local machine
- SQLite database
- File-based storage
- Streamlit development server

**Staging Environment:**
- Cloud VM (AWS EC2, GCP Compute Engine, DigitalOcean)
- PostgreSQL database
- Cloud storage (S3/GCS) for files
- Docker containers
- HTTPS with Let's Encrypt

**Production Environment:**
- Kubernetes cluster (future) or cloud VM
- Managed PostgreSQL (AWS RDS, GCP Cloud SQL)
- CDN for static assets
- Load balancer
- Auto-scaling (future)

### 13.2 Deployment Process

**Containerization (Docker):**

```dockerfile
# Dockerfile example
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 8501
CMD ["streamlit", "run", "frontend/streamlit/app.py"]
```

**Docker Compose:**

```yaml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "8501:8501"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/mathanoshto
    volumes:
      - ./uploads:/app/uploads
      - ./data:/app/data
  db:
    image: postgres:15
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=mathanoshto
    volumes:
      - pgdata:/var/lib/postgresql/data
volumes:
  pgdata:
```

**CI/CD Pipeline:**
- **Source Control:** Git (GitHub/GitLab)
- **CI:** GitHub Actions, GitLab CI
- **Steps:**
  1. Lint and format check (black, flake8)
  2. Run unit tests
  3. Build Docker image
  4. Push to container registry
  5. Deploy to staging
  6. Run integration tests
  7. Manual approval for production
  8. Deploy to production

**Deployment Steps:**
1. Pull latest code
2. Install dependencies
3. Run database migrations
4. Restart application
5. Health check
6. Rollback on failure

### 13.3 Monitoring & Logging

**Application Monitoring:**
- Health check endpoint (`/health`)
- Uptime monitoring (UptimeRobot, Pingdom)
- Response time tracking
- Error rate monitoring

**Logging:**
- Application logs (Python logging module)
- Access logs (Nginx/Apache)
- Error logs (Sentry for exception tracking)
- Log aggregation (ELK stack, CloudWatch)

**Metrics:**
- Request count per endpoint
- Average response time
- Error rate
- Database query performance
- LLM API call counts and costs

**Alerting:**
- Email/Slack alerts for:
  - Application downtime
  - High error rates (>5%)
  - Slow response times (>5 seconds)
  - Database connection failures
  - Disk space low (<10%)

### 13.4 Backup & Recovery

**Automated Backups:**
- Database: Daily at 2 AM UTC
- Files: Weekly on Sundays
- ChromaDB: Weekly on Sundays
- Retention: 7 days (database), 30 days (files)

**Backup Storage:**
- Primary: Cloud storage (S3/GCS)
- Secondary: Separate region for disaster recovery

**Recovery Procedures:**
1. **Database Recovery:**
   - Stop application
   - Restore from latest backup
   - Run migrations if needed
   - Start application
   - Verify functionality

2. **File Recovery:**
   - Restore files from backup
   - Update file paths if needed
   - Verify file accessibility

3. **Disaster Recovery:**
   - Provision new infrastructure
   - Restore database and files
   - Update DNS
   - Verify all systems operational

**Recovery Time Objective (RTO):** 4 hours
**Recovery Point Objective (RPO):** 24 hours (daily backups)

### 13.5 Scaling Strategy

**Vertical Scaling (Short-term):**
- Increase server resources (CPU, RAM)
- Optimize database (indexing, query optimization)
- Use database connection pooling

**Horizontal Scaling (Long-term):**
- Multiple application instances behind load balancer
- Separate services (API, frontend, workers)
- Database read replicas
- Caching layer (Redis)

**Cost Optimization:**
- Right-size instances
- Use spot/preemptible instances for non-critical workloads
- Monitor LLM API costs, optimize token usage
- Implement caching for repeated queries

---

## 14. Future Roadmap

### 14.1 Short-term (3-6 months)

**Enhanced Features:**
- [ ] FastAPI REST API for programmatic access
- [ ] Streamlit UI components for all smart features
- [ ] Agent marketplace (share and import agents)
- [ ] Memory export/import
- [ ] Multi-modal RAG (images, tables in documents)
- [ ] Real-time collaboration (shared conversations)

**Performance & Scalability:**
- [ ] Redis caching layer
- [ ] Background task processing (Celery)
- [ ] Async database operations
- [ ] Query optimization and indexing

**User Experience:**
- [ ] Mobile-responsive UI improvements
- [ ] Customizable UI themes
- [ ] Voice input support
- [ ] Keyboard shortcuts
- [ ] Notification system

### 14.2 Mid-term (6-12 months)

**Intelligence & AI:**
- [ ] Fine-tuned models for specific tasks
- [ ] Multi-agent collaboration (agents working together)
- [ ] Automatic prompt engineering
- [ ] Conversation branching and merging
- [ ] Knowledge graph visualization

**Integration:**
- [ ] Slack/Discord bot integration
- [ ] Browser extension
- [ ] Mobile app (React Native/Flutter)
- [ ] VS Code extension
- [ ] API integrations (Notion, Google Drive, etc.)

**Enterprise Features:**
- [ ] Team workspaces
- [ ] Role-based access control (RBAC)
- [ ] Audit logging
- [ ] SSO integration (SAML, OAuth)
- [ ] Usage analytics and reporting

### 14.3 Long-term (12+ months)

**Platform Evolution:**
- [ ] Open API ecosystem (plugin system)
- [ ] Marketplace for tools and integrations
- [ ] White-label deployment options
- [ ] Self-hosted enterprise version
- [ ] Distributed architecture (microservices)

**Advanced AI:**
- [ ] Multi-modal fusion (text + image + audio)
- [ ] Custom model training pipeline
- [ ] Federated learning for privacy
- [ ] Reinforcement learning from human feedback (RLHF)
- [ ] Autonomous agents (long-running tasks)

**Business & Community:**
- [ ] Freemium pricing model
- [ ] Team/enterprise plans
- [ ] Community forum
- [ ] Developer documentation portal
- [ ] Integration partner program

---

## 15. Glossary

**Agent:** A specialized AI persona with custom system prompts, parameters, and tool permissions designed for specific tasks or domains.

**BM25:** A ranking function used in information retrieval, particularly effective for keyword-based search.

**ChromaDB:** An open-source vector database optimized for storing and retrieving embeddings.

**Chunking:** The process of splitting documents into smaller segments for processing and retrieval in RAG systems.

**Citation:** A reference to the source document and location (page, section) from which information was retrieved.

**Embedding:** A numerical vector representation of text that captures semantic meaning, used for similarity search.

**Firecrawl:** A web scraping service that handles JavaScript-rendered pages and complex web applications.

**LLM (Large Language Model):** An AI model trained on vast amounts of text data, capable of understanding and generating human-like text (e.g., GPT-4, Gemini, Claude).

**Markdown:** A lightweight markup language for formatting text, commonly used for documentation and chat interfaces.

**Memory:** Information stored about the user (preferences, facts, context) for long-term recall across conversations.

**MMR (Maximal Marginal Relevance):** A re-ranking algorithm that balances relevance and diversity in retrieved results.

**Multimodal:** The ability to process and understand multiple types of data (text, images, audio, etc.).

**Provider:** A service that offers LLM APIs (e.g., OpenAI, Google, Anthropic).

**RAG (Retrieval-Augmented Generation):** A technique that enhances LLM responses by retrieving relevant information from a knowledge base before generation.

**Re-ranking:** The process of reordering retrieved results based on additional criteria (e.g., diversity, relevance).

**RRF (Reciprocal Rank Fusion):** A method for combining rankings from multiple retrieval systems.

**Semantic Search:** Search based on meaning and context rather than exact keyword matches.

**Session State:** Persistent state information maintained across interactions in a user session.

**SQLAlchemy:** A Python SQL toolkit and Object-Relational Mapping (ORM) library.

**Streamlit:** A Python framework for building data applications and web UIs.

**System Prompt:** Initial instructions given to an LLM that define its role, behavior, and constraints.

**Tavily:** A web search API optimized for AI applications, providing AI-generated summaries.

**Token:** The basic unit of text processing in LLMs (roughly a word or subword).

**Tool:** An external capability that the AI can invoke (e.g., web search, calculator, database query).

**Vector Database:** A database optimized for storing and querying high-dimensional vectors (embeddings).

**Vision Model:** An LLM that can process and understand images in addition to text (e.g., GPT-4V, Gemini Vision).

---

## Document Change History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-11-12 | Development Team | Initial PRD creation |

---

## Approval

**Product Manager:** _______________ Date: ___________

**Engineering Lead:** _______________ Date: ___________

**QA Lead:** _______________ Date: ___________

---

**End of Document**


